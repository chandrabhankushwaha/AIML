{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Problem statement -Campus Recruitment\n",
    "\n",
    "Follow the Data Science Methodology. Analyze the data set and identify the parameters that affects the campus recruitment and predict the salary. Answer the questions like \n",
    "Which factor influenced a candidate in getting placed? \n",
    "Do percentage matters for one to get placed? \n",
    "Which degree specialization is much demanded by corporate?\n",
    "\n",
    "Below Questions need to be answer\n",
    "\n",
    "1) Write a Data Science Proposal for achieving the objective mentioned. \n",
    "2) Perform exploratory analysis on the data and describe your understanding of the data. \n",
    "3) Perform data pre-processing. E.g., missing data, normalization, discretization, etc.,. \n",
    "4) Apply any two feature selection engineering techniques \n",
    "5) Compare the two selected feature engineering techniques. \n",
    "6) Use Any regression techniques you have studied to predict. \n",
    "7) Compare the performance of the regression technique before and after applying the pre-processing and feature engineering techniques. \n",
    "8) Present the conclusions/results (Answers to the above-mentioned objectives and tasks) in the format shared. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions/Objective"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Which factor influenced a candidate in getting placed? \n",
    "Do percentage matters for one to get placed? \n",
    "Which degree specialization is much demanded by corporate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will import the libraries required to complete our task and get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports required libraries\n",
    "** Import pandas, numpy, matplotlib,and seaborn. Then set %matplotlib inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn import linear_model\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline\n",
    "# machine learning\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score,precision_score\n",
    "from sklearn.metrics import accuracy_score ,precision_score,recall_score,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data\n",
    "We'll work with selecting a candidate in Campus recruitment Prediction data csv file It has S.No, Gender, ssc percentage, hsc percentage, degree, work exp, specialization, mba percentage status , salary\n",
    "** Read iCampus recruitment Prediction data csv file as a DataFrame called df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Placement_Data_Full_Class-1.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Perform exploratory analysis on the data and describe your understanding of the data\n",
    ". \n",
    "Let us quickly view the first few rows and extract some prelimindary information about the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at data using head method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sl_no gender  ssc_p    ssc_b  hsc_p    hsc_b     hsc_s  degree_p  \\\n",
      "0        1      M  67.00   Others  91.00   Others  Commerce     58.00   \n",
      "1        2      M  79.33  Central  78.33   Others   Science     77.48   \n",
      "2        3      M  65.00  Central  68.00  Central      Arts     64.00   \n",
      "3        4      M  56.00  Central  52.00  Central   Science     52.00   \n",
      "4        5      M  85.80  Central  73.60  Central  Commerce     73.30   \n",
      "..     ...    ...    ...      ...    ...      ...       ...       ...   \n",
      "210    211      M  80.60   Others  82.00   Others  Commerce     77.60   \n",
      "211    212      M  58.00   Others  60.00   Others   Science     72.00   \n",
      "212    213      M  67.00   Others  67.00   Others  Commerce     73.00   \n",
      "213    214      F  74.00   Others  66.00   Others  Commerce     58.00   \n",
      "214    215      M  62.00  Central  58.00   Others   Science     53.00   \n",
      "\n",
      "      degree_t workex  etest_p specialisation  mba_p      status    salary  \n",
      "0     Sci&Tech     No     55.0         Mkt&HR  58.80      Placed  270000.0  \n",
      "1     Sci&Tech    Yes     86.5        Mkt&Fin  66.28      Placed  200000.0  \n",
      "2    Comm&Mgmt     No     75.0        Mkt&Fin  57.80      Placed  250000.0  \n",
      "3     Sci&Tech     No     66.0         Mkt&HR  59.43  Not Placed       NaN  \n",
      "4    Comm&Mgmt     No     96.8        Mkt&Fin  55.50      Placed  425000.0  \n",
      "..         ...    ...      ...            ...    ...         ...       ...  \n",
      "210  Comm&Mgmt     No     91.0        Mkt&Fin  74.49      Placed  400000.0  \n",
      "211   Sci&Tech     No     74.0        Mkt&Fin  53.62      Placed  275000.0  \n",
      "212  Comm&Mgmt    Yes     59.0        Mkt&Fin  69.72      Placed  295000.0  \n",
      "213  Comm&Mgmt     No     70.0         Mkt&HR  60.23      Placed  204000.0  \n",
      "214  Comm&Mgmt     No     89.0         Mkt&HR  60.22  Not Placed       NaN  \n",
      "\n",
      "[215 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets see the features in given sample data by using columns method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Columns in data\n",
      "==================================================\n",
      "['sl_no' 'gender' 'ssc_p' 'ssc_b' 'hsc_p' 'hsc_b' 'hsc_s' 'degree_p'\n",
      " 'degree_t' 'workex' 'etest_p' 'specialisation' 'mba_p' 'status' 'salary']\n"
     ]
    }
   ],
   "source": [
    "print('='*50)\n",
    "print(\"Columns in data\")\n",
    "print('='*50)\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we have below coloums/feature in our dataset\n",
    "Let's have look at each column information.\n",
    "sl_no : Serial Number\n",
    "\n",
    "gender : Candidate gender --> Male='M',Female='F'\n",
    "\n",
    "ssc_p : SSC (10th) Percentage\n",
    "\n",
    "ssc_b : SSC Board of Education --> Central (or) Others\n",
    "\n",
    "hsc_p : HSC (12th) percentage\n",
    "\n",
    "hsc_b : HSC Board of Education --> Central/ Others\n",
    "\n",
    "hsc_s : Specialization in HSC\n",
    "\n",
    "degree_p : Degree Percentage\n",
    "\n",
    "degree_t : Under Graduation (Degree type)- Field of degree education\n",
    "\n",
    "workex : Work Experience\n",
    "etest_p : Employability test percentage ( conducted by college)\n",
    "\n",
    "specialisation : Post Graduation(MBA)- Specialization\n",
    "\n",
    "mba_p : MBA percentage\n",
    "\n",
    "status : Status of placement- Placed/Not placed\n",
    "\n",
    "salary : Salary offered by corporate to candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets find out How many Data we have in our data set using shape method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Data shape\n",
      "====================\n",
      "(215, 15)\n"
     ]
    }
   ],
   "source": [
    "print('='*20)\n",
    "print(\"Data shape\")\n",
    "print('='*20)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have only 215 samples in our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl_no</th>\n",
       "      <th>ssc_p</th>\n",
       "      <th>hsc_p</th>\n",
       "      <th>degree_p</th>\n",
       "      <th>etest_p</th>\n",
       "      <th>mba_p</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>67.303395</td>\n",
       "      <td>66.333163</td>\n",
       "      <td>66.370186</td>\n",
       "      <td>72.100558</td>\n",
       "      <td>62.278186</td>\n",
       "      <td>288655.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>62.209324</td>\n",
       "      <td>10.827205</td>\n",
       "      <td>10.897509</td>\n",
       "      <td>7.358743</td>\n",
       "      <td>13.275956</td>\n",
       "      <td>5.833385</td>\n",
       "      <td>93457.452420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.890000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>51.210000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>22.400000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>55.802000</td>\n",
       "      <td>54.986000</td>\n",
       "      <td>217400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54.500000</td>\n",
       "      <td>60.600000</td>\n",
       "      <td>60.900000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>57.945000</td>\n",
       "      <td>240000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>265000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>161.500000</td>\n",
       "      <td>75.700000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>83.500000</td>\n",
       "      <td>66.255000</td>\n",
       "      <td>300000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>215.000000</td>\n",
       "      <td>89.400000</td>\n",
       "      <td>97.700000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>77.890000</td>\n",
       "      <td>940000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sl_no       ssc_p       hsc_p    degree_p     etest_p       mba_p  \\\n",
       "count  215.000000  215.000000  215.000000  215.000000  215.000000  215.000000   \n",
       "mean   108.000000   67.303395   66.333163   66.370186   72.100558   62.278186   \n",
       "std     62.209324   10.827205   10.897509    7.358743   13.275956    5.833385   \n",
       "min      1.000000   40.890000   37.000000   50.000000   50.000000   51.210000   \n",
       "10%     22.400000   52.000000   52.000000   57.000000   55.802000   54.986000   \n",
       "25%     54.500000   60.600000   60.900000   61.000000   60.000000   57.945000   \n",
       "50%    108.000000   67.000000   65.000000   66.000000   71.000000   62.000000   \n",
       "75%    161.500000   75.700000   73.000000   72.000000   83.500000   66.255000   \n",
       "max    215.000000   89.400000   97.700000   91.000000   98.000000   77.890000   \n",
       "\n",
       "              salary  \n",
       "count     148.000000  \n",
       "mean   288655.405405  \n",
       "std     93457.452420  \n",
       "min    200000.000000  \n",
       "10%    217400.000000  \n",
       "25%    240000.000000  \n",
       "50%    265000.000000  \n",
       "75%    300000.000000  \n",
       "max    940000.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Checking Min, Max, Mean, Std for all the columns\n",
    "df.describe(percentiles=[.10, .25, .5, .75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let see data object Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\n",
      "Data Information\n",
      "\n",
      "==================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 215 entries, 0 to 214\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   sl_no           215 non-null    int64  \n",
      " 1   gender          215 non-null    object \n",
      " 2   ssc_p           215 non-null    float64\n",
      " 3   ssc_b           215 non-null    object \n",
      " 4   hsc_p           215 non-null    float64\n",
      " 5   hsc_b           215 non-null    object \n",
      " 6   hsc_s           215 non-null    object \n",
      " 7   degree_p        215 non-null    float64\n",
      " 8   degree_t        215 non-null    object \n",
      " 9   workex          215 non-null    object \n",
      " 10  etest_p         215 non-null    float64\n",
      " 11  specialisation  215 non-null    object \n",
      " 12  mba_p           215 non-null    float64\n",
      " 13  status          215 non-null    object \n",
      " 14  salary          148 non-null    float64\n",
      "dtypes: float64(6), int64(1), object(8)\n",
      "memory usage: 25.3+ KB\n"
     ]
    }
   ],
   "source": [
    "print('='*50)\n",
    "print(\"\\nData Information\\n\")\n",
    "print('='*50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have 7 columns with real values and 8 with object datatype\n",
    "\n",
    "#As it is clear that we don't need sl_no in training model or in EDA.\n",
    "#Thus I am dropping sl_no column. Rest of them I will keep as it is.\n",
    "#After performing EDA I will drop other if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(['sl_no'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'column' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6352\\1929268948.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# column=df.select_dtypes(include=['object'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'column' is not defined"
     ]
    }
   ],
   "source": [
    "# column=df.select_dtypes(include=['object'])\n",
    "for col in column:\n",
    "    display(data[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBSERVATION:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERVATION:\n",
    "Looks like except for hsc_s and degree_t with 3 classes, all other have 2 classes each and also we can see that this data is slightly imbalanced as we have 148 placed students and 67 not placed students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # It is clear that only salary has null columns. Let's see how much?We need to clean the nan value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percantage=df['salary'].isnull().sum()/len(df)*100\n",
    "\n",
    "print(round(missing_percantage,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that around 31% candidates were not placed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From above it seems 31.16 % of candidates were not placed.\n",
    "For perdicting the salary as per our Assignment objective i will hanadle it as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary'].fillna(0, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After cleaning the null value. Lets once again check the null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All null valaues are cleared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of duplicate values in the dataset is : \", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since duplicate dataset is 0 , No need to handle it.we can proceed with exploring the feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let Check for Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers are unusual values in your dataset, and they can distort statistical analyses and violate their assumptions.\n",
    "let's first visualize our data and decide on what to do with the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "plt.style.use('seaborn-white')\n",
    "ax=plt.subplot(221)\n",
    "plt.boxplot(df['ssc_p'])\n",
    "ax.set_title('Secondary school percentage')\n",
    "ax=plt.subplot(222)\n",
    "plt.boxplot(df['hsc_p'])\n",
    "ax.set_title('Higher Secondary school percentage')\n",
    "ax=plt.subplot(223)\n",
    "plt.boxplot(df['degree_p'])\n",
    "ax.set_title('UG Degree percentage')\n",
    "ax=plt.subplot(224)\n",
    "plt.boxplot(df['etest_p'])\n",
    "ax.set_title('Employability percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, we have very less number of outliers in our features. Especially we have majority of the outliers in hsc percentage Let's clear em up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['hsc_p'].quantile(0.25)\n",
    "Q3 = df['hsc_p'].quantile(0.75)\n",
    "IQR = Q3 - Q1    #IQR is interquartile range. \n",
    "\n",
    "filter = (df['hsc_p'] >= Q1 - 1.5 * IQR) & (df['hsc_p'] <= Q3 + 1.5 *IQR)\n",
    "placement_filtered=df.loc[filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing Outlier Graphs look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 5))\n",
    "plt.style.use('seaborn-white')\n",
    "ax=plt.subplot(121)\n",
    "plt.boxplot(df['hsc_p'])\n",
    "ax.set_title('Before removing outliers(hsc_p)')\n",
    "ax=plt.subplot(122)\n",
    "plt.boxplot(placement_filtered['hsc_p'])\n",
    "ax.set_title('After removing outliers(hsc_p)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Exploratory Data Analysis(EDA) & Visualizations of Data by each Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature:- Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "plt.subplot(1,2,1)\n",
    "df['status'].value_counts().plot(kind = 'pie', autopct = '%.2f%%')\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x = 'status', data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From above plot we can see 68.84 % of students are placed and 31.16 % Student are not placed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature:-Gender\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check whethere gender affect on placement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of 215 candidates, 139 are male and 76 are female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.countplot(x = 'gender', hue='status',data = df)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.groupby(['gender','status'])['status'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.boxplot(y='gender',x='salary',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBSERVATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Male have high chances of getting placed compared to females.\n",
    "#We have samples of 139 Male studets and 76 Female students.\n",
    "#The number of male students are almost double as compared to female.\n",
    "#More outliers on Male,Male students are getting high CTC jobs.\n",
    "#Male students are offered slightly greater salary than female on an average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature : ssc_b,hsc_b,hsc_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does the board of education affect placements?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSC Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ssc_b'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc_b_count=pd.DataFrame(data.groupby(['ssc_b','status'])['status'].count())\n",
    "ssc_b_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='ssc_b', hue='status', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the above analysis I can say that, SSC board is not important to recruiters when it come to hiring candidates. So I am not going to use this feature while training model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSC Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hsc_b'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsc_board_count = pd.DataFrame(data.groupby(['hsc_b','status'])['status'].count())\n",
    "hsc_board_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='hsc_b', hue='status', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the above analysis I can say that, SSC board is not important to recruiters when it come to hiring candidates. So I am not going to use this feature while training model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSC_S Specialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hsc_s'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsc_specialization_count = pd.DataFrame(data.groupby(['hsc_s','status'])['status'].count())\n",
    "hsc_specialization_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='hsc_s', hue='status', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.catplot(x='hsc_b',hue='hsc_s',col='status',data=df,kind='count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observetion:for various boards"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "There is count of central board students is very high as compared to all other boards in ssc_b but its reverse in hsc_b.\n",
    "Look like not much difference between in the fraction of placed candidates in respective boards.\n",
    "Board doesn't matter in placements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature : ssc_p,hsc_p,degree_p,mba_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does your academic score influence your chance of placement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  SSC Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data['ssc_p'], kde=False)\n",
    "plt.title('Distribution of SSC Percentage')\n",
    "plt.xlabel('SSC %')\n",
    "\n",
    "\n",
    "sns.distplot(data.ssc_p[data.status=='Not Placed'])\n",
    "sns.distplot(data.ssc_p[data.status=='Placed'])\n",
    "plt.legend(['Not placed','placed'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y='ssc_p', x='status', data=df)\n",
    "plt.xlabel('Employment Status')\n",
    "plt.ylabel('SSC %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Students who are place have higer percentage in SSC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  HSC Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['hsc_p'], kde=False)\n",
    "plt.title('Distribution of SSC Percentage')\n",
    "plt.xlabel('HSC %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y='hsc_p', x='status', data=df)\n",
    "plt.xlabel('Employment Status')\n",
    "plt.ylabel('HSC %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HSC percentage are important features. As all placed students have higher percentages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Degree Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['degree_p'], kde=False)\n",
    "plt.title('Distribution of Degree Percentage')\n",
    "plt.xlabel('Degree %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y='degree_p', x='status', data=df)\n",
    "plt.xlabel('Employment Status')\n",
    "plt.ylabel('Degree %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like SSC and HSC percentages, Degree Percentages are also impotant factor to get placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 15))\n",
    "ax=plt.subplot(221)\n",
    "sns.boxplot(x='status',y='ssc_p',data=df)\n",
    "ax.set_title('Secondary school percentage')\n",
    "ax=plt.subplot(222)\n",
    "sns.boxplot(x='status',y='hsc_p',data=df)\n",
    "ax.set_title('Higher Secondary school percentage')\n",
    "ax=plt.subplot(223)\n",
    "sns.boxplot(x='status',y='degree_p',data=df)\n",
    "ax.set_title('UG Degree percentage')\n",
    "ax=plt.subplot(224)\n",
    "sns.boxplot(x='status',y='mba_p',data=df)\n",
    "ax.set_title('MBA percentage')\n",
    "\n",
    "#Distribution of all percentages\n",
    "plt.figure(figsize = (15, 7))\n",
    "plt.style.use('seaborn-white')\n",
    "plt.subplot(231)\n",
    "sns.distplot(df['ssc_p'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "plt.subplot(232)\n",
    "sns.distplot(df['hsc_p'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "plt.subplot(233)\n",
    "sns.distplot(df['degree_p'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(235)\n",
    "sns.distplot(df['mba_p'])\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "#plt.subplot(236)\n",
    "#sns.distplot(df['salary'])\n",
    "#fig = plt.gcf()\n",
    "#fig.set_size_inches(10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBSERVATION For Percentage :-"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Most of the candidates educational performances are between 60-80%\n",
    "We can see that getting good percentages in MBA does not guarantee placement of the candidate.\n",
    "Comparitively there's a slight difference between the percentage scores between both the groups, But still placed candidates still has an upper hand. So as per the plot,percentage do not influence the placement status\n",
    "#### These percentages don't have any influence over their salary.\n",
    "All the distributions follow normal distribution except salary feature\n",
    "Most of the candidates educational performances are between 60-80%\n",
    "Salary distribution got outliers where few have got salary of 7.5L and 10L PA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Degree Type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['degree_t'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_count = pd.DataFrame(data.groupby(['degree_t','status'])['status'].count())\n",
    "degree_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='degree_t', hue='status', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['workex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_exp= pd.DataFrame(data.groupby(['workex','status'])['status'].count())\n",
    "work_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='workex', hue='status', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBSERVATION From Work Experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It is clear that candidate with work experience have higher chance of getting placed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employment Test Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['etest_p'], kde=False)\n",
    "plt.title('Distribution of MBA Percentage')\n",
    "plt.xlabel('Employment Test %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y='etest_p', x='status', data=df)\n",
    "plt.xlabel('Employment Status')\n",
    "plt.ylabel('Employment Test %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBA Specialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['specialisation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialization_count_placed= pd.DataFrame(data.groupby(['specialisation','status'])['status'].count())\n",
    "specialization_count_placed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='specialisation', hue='status', data=df)\n",
    "plt.xlabel('MBA Specialization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From above we can see student who has opted MBA in Mkt and Finance has higher chnance of placed and get salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBA Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['mba_p'], kde=False)\n",
    "plt.title('Distribution of MBA Percentage')\n",
    "plt.xlabel('MBA %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y='mba_p', x='status', data=df)\n",
    "plt.xlabel('Employment Status')\n",
    "plt.ylabel('MBA %')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From above we can see student who higher percentagae has higher chnance of placed and get salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Important Factor; Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary'].fillna(-1, inplace=True)\n",
    "sns.distplot(df['salary'], kde=False)\n",
    "plt.title('Distribution of Salary')\n",
    "plt.xlabel('Salary')\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.distplot(df['salary'], bins=50, hist=False)\n",
    "plt.title(\"Salary Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y='salary', x='status', data=df)\n",
    "plt.xlabel('Employment Status')\n",
    "plt.ylabel('Salary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation from salary :-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at the distribution we can say that the most of the students get a package between 200k-400k and most salaries above 400,000 are outliers.\n",
    "\n",
    "\n",
    "Male candidates are making more money as compared to female candidates.\n",
    "Only one candidate got around 10L PA\n",
    "The average of the salary is a little more than 2LPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Correlation between features & Various Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Correlation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df[['ssc_p','hsc_p','degree_p', 'etest_p','mba_p','salary', 'status']], hue=\"status\", diag_kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will convert all string data types into numeric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy original dataset into another varialble to build model without feature engineering\n",
    "df_without_fe = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_fe.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert string data into categoary data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_fe[\"gender\"] = df_without_fe[\"gender\"].astype('category')\n",
    "df_without_fe[\"ssc_b\"] = df_without_fe[\"ssc_b\"].astype('category')\n",
    "df_without_fe[\"hsc_b\"] = df_without_fe[\"hsc_b\"].astype('category')\n",
    "df_without_fe[\"hsc_s\"] = df_without_fe[\"hsc_s\"].astype('category')\n",
    "df_without_fe[\"degree_t\"] = df_without_fe[\"degree_t\"].astype('category')\n",
    "df_without_fe[\"workex\"] = df_without_fe[\"workex\"].astype('category')\n",
    "df_without_fe[\"specialisation\"] = df_without_fe[\"specialisation\"].astype('category')\n",
    "df_without_fe[\"status\"] = df_without_fe[\"status\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_fe.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Convert  category data type to numeric data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of each category\n",
    "dict_gender = dict(enumerate(df_without_fe[\"gender\"].cat.categories))\n",
    "dict_ssc_b = dict(enumerate(df_without_fe[\"ssc_b\"].cat.categories))\n",
    "dict_hsc_b = dict(enumerate(df_without_fe[\"hsc_b\"].cat.categories))\n",
    "dict_hsc_s = dict(enumerate(df_without_fe[\"hsc_s\"].cat.categories))\n",
    "dict_degree_t = dict(enumerate(df_without_fe[\"degree_t\"].cat.categories))\n",
    "dict_workex = dict(enumerate(df_without_fe[\"workex\"].cat.categories))\n",
    "dict_specialisation = dict(enumerate(df_without_fe[\"specialisation\"].cat.categories))\n",
    "dict_status = dict(enumerate(df_without_fe[\"status\"].cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dictionary of gender          : ', dict_gender)\n",
    "print('Dictionary of ssc_b           : ', dict_ssc_b)\n",
    "print('Dictionary of hsc_b           : ', dict_hsc_b)\n",
    "print('Dictionary of hsc_s           : ', dict_hsc_s)\n",
    "print('Dictionary of degree_t        : ', dict_degree_t)\n",
    "print('Dictionary of workex          : ', dict_workex)\n",
    "print('Dictionary of specialisation  : ', dict_specialisation)\n",
    "print('Dictionary of status          : ', dict_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_fe[\"gender\"] = df_without_fe[\"gender\"].cat.codes\n",
    "df_without_fe[\"ssc_b\"] = df_without_fe[\"ssc_b\"].cat.codes\n",
    "df_without_fe[\"hsc_b\"] = df_without_fe[\"hsc_b\"].cat.codes\n",
    "df_without_fe[\"hsc_s\"] = df_without_fe[\"hsc_s\"].cat.codes\n",
    "df_without_fe[\"degree_t\"] = df_without_fe[\"degree_t\"].cat.codes\n",
    "df_without_fe[\"workex\"] = df_without_fe[\"workex\"].cat.codes\n",
    "df_without_fe[\"specialisation\"] = df_without_fe[\"specialisation\"].cat.codes\n",
    "df_without_fe[\"status\"] = df_without_fe[\"status\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_fe.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression-Prediction of Salary Before Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Spliting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['gender', 'ssc_p', 'ssc_b', 'hsc_p', 'hsc_b', 'hsc_s', 'degree_p', 'degree_t', 'workex', 'etest_p', 'specialisation', 'mba_p']\n",
    "output_column = ['salary']\n",
    "\n",
    "X = df_without_fe[feature_columns]\n",
    "y = df_without_fe[output_column]\n",
    "\n",
    "#y = df_without_fe['salary']\n",
    "#X = df_without_fe.copy().drop('status', axis=1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As different columns have different range of values hence dominance of few columns will be there in dataset. To avoid this we are converting it into standarize format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model using linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "#regr.fit(X_train, Y_train.ravel())\n",
    "regr.fit(X_train,y_train)\n",
    "\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "print('Intercept: \\n', regr.intercept_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Test Data & Execute ML model on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regr.predict( X_test)\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,predictions)\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('Predicted Y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's evaluate our model performance by calculating the residual sum of squares and the explained variance score (R^2).\n",
    "\n",
    "** Calculate the Mean Absolute Error, Mean Squared Error, and the Root Mean Squared Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate these metrics by hand!\n",
    "from sklearn import metrics\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:',metrics.explained_variance_score(y_test, predictions))\n",
    "\n",
    "print('Accuracy Before FE:',regr.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuray of model is approx 30.11% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will also try linear regression,With OLS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For linear regression, we are using OLS from statsmodel package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['gender', 'ssc_p', 'ssc_b', 'hsc_p', 'hsc_b', 'hsc_s', 'degree_p', 'degree_t', 'workex', 'etest_p', 'specialisation', 'mba_p']\n",
    "output_column = ['salary']\n",
    "\n",
    "x= df_without_fe[feature_columns]\n",
    "y = df_without_fe[output_column]\n",
    "#y = df_without_fe['salary']\n",
    "#x = df_without_fe.copy().drop('status', axis=1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(x,y , test_size=0.2, random_state=42)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = sm.OLS(train_y,train_x.astype(float))\n",
    "results = linear_model.fit()\n",
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = results.predict(test_x)\n",
    "# print(pred_y[:10])\n",
    "# print(test_y[:10])\n",
    "\n",
    "col = ['actual','prediction']\n",
    "\n",
    "prediction = pd.concat([test_y,pred_y],axis=1)\n",
    "prediction.columns = col\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(x = range(0, test_y.size), y=test_y, c = 'blue', label = 'Actual', alpha = 0.3)\n",
    "ax.scatter(x = range(0, pred_y.size), y=pred_y, c = 'red', label = 'Predicted', alpha = 0.3)\n",
    "\n",
    "plt.title('Actual and predicted values')\n",
    "plt.xlabel('Observations')\n",
    "plt.ylabel('Salary')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics With OLS withOut Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(test_y, pred_y))\n",
    "print('MSE:', metrics.mean_squared_error(test_y, pred_y))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(test_y, pred_y)))\n",
    "print('R2:',metrics.explained_variance_score(test_y, pred_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature mapping and generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop all unwanted columns as menstioned in above section.\n",
    "\n",
    "SSC Board\n",
    "HSC Board\n",
    "HSC Specialisation\n",
    "Degree Type\n",
    "Salart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['ssc_b','hsc_b', 'hsc_s', 'degree_t'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's map categorical feature to numeric one. Categorical features:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dummy variable is a categorical variable that has been transformed into numeric. \n",
    "For example the column Gender, we have \"male\" and \"female\" we will transform these variables into numeric.\n",
    "Creating a new column just for Men. and Women, where 1 will be set to positive and 0 to negative"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Gender : Gender feature have male and female values. I am going to map 0 for male and 1 for female.\n",
    "Work Experience : Work Experience feature have Yes and No values. I am going to map 0 for No and 1 for Yes.\n",
    "Status : Status feature have Not Placed and Placed values. Again for this features I am mapping 0 for not placed and 1 for placed values.\n",
    "Specialisation : Specialisation feature have two values Mkt&HR and Mkt&Fin. I am going to map 0 to Mkt&HR and 1 to Mkt&Fin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# exrtact categorical features\n",
    "\n",
    "cat_col=df.select_dtypes(object).columns.tolist()\n",
    "len(cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorized values to numerical values\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[cat_col] =df[cat_col].astype('str').apply(le.fit_transform)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gender\"] = data.gender.map({\"M\":0,\"F\":1})\n",
    "df[\"workex\"] = data.workex.map({\"No\":0, \"Yes\":1})\n",
    "df[\"status\"] = data.status.map({\"Not Placed\":0, \"Placed\":1})\n",
    "df[\"specialisation\"] = data.specialisation.map({\"Mkt&HR\":0, \"Mkt&Fin\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Apply 2 feature selection engineering techniques and Compare the two selected feature engineering techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Chi-Sqaured for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_scores, p_values = chi2(df.iloc[:,:-2],df.iloc[:,-2])\n",
    "print(\"Columns of dataframe: \\b\", df.iloc[:,:-2].columns)\n",
    "print(\"Chi-Squared Scores : \\n\",chi2_scores)\n",
    "print(\"\\np values : \\n\",p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:25} {:25} {:25}\".format('FeatureName','Chi-Squared Scores', 'p values'))\n",
    "for f_name, chi_score, p_value in zip(df.iloc[:,:-2], chi2_scores, p_values):\n",
    "    print(\"{:25} {:25} {:25}\".format(str(f_name), str(chi_score), str(p_value)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If value of Chi-Squared score is higher it means output is highly dependent on that feature. Please find key updates regarding feature\n",
    "- **ssc_p :** Chi-Squared score is the highest for this features that is **137.73925800375304**. Becuse of that this is the most important feature\n",
    "- **hsc_p :** This is the second most important feature for output with Chi-Squared score of **92.44931180755225**\n",
    "- **mba_p :** This is least important feature as per the Chi-Squared score which **0.6918567933507178**\n",
    "\n",
    "- **Please find below importance of feature from higher to lower using Chi-Squared score**\n",
    "\n",
    "| Feature name | Chi-Squared score |\n",
    "| --- | -: |\n",
    "|\tgender                    \t|\t5.532155289618014         \t|\n",
    "|\tssc_p                     \t|\t137.73925800375304                    \t|\n",
    "|\thsc_p                                          \t|\t92.44931180755225\t|\n",
    "|\tdegree_p\t|\t40.20489567530576|\n",
    "|\tworkex                    \t|\t10.745483684572026\t|\n",
    "|\tetest_p                   \t|\t8.522678737307453\t|\n",
    "|\tspecialisation            \t|\t5.968657556810542\t|\n",
    "|\tmba_p                     \t|\t0.6918567933507178\t|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation is a statistical technique that can show whether and how strongly pairs of variables are related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(df.corr(),annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Candidates with Higher MBA Percentage have a higher chance of getting Placed.\n",
    "\n",
    "Again Higher SSC Percentage is also beneficial for Placement.\n",
    "\n",
    "Higher HSC Percentage and Degree Percentage also plays a Significant role in Placement.\n",
    "\n",
    "Surprisingly E Test Percentage does not affect a candidate's Placement Outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing feture selection techniques : Chi-Sqaured for feature selection vs correlation coefficient \n",
    "- **Chi-Sqaured for feature selection :** This technique provided five best features those are `ssc_p                     , hsc_p , workex , degree_p, etest_p `\n",
    "- **Correlation Coefficient :** This technique provided five best features those are `ssc_p, hsc_p, hsc_s, degree_p, workex`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1. Additional feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_features(df):\n",
    "    df['hsc_to_ssc'] = df['hsc_p'] / df['ssc_p']\n",
    "    df['degree_to_hsc'] = df['degree_p'] / df['hsc_p']\n",
    "    df['degree_to_ssc'] = df['degree_p'] / df['ssc_p']\n",
    "    df['mba_to_degree'] = df['mba_p'] / df['degree_p']\n",
    "    df['mba_to_etest'] = df['mba_p'] / df['etest_p']\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_data = new_features(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will now select the features (X) for our model. These features will help our model identify patterns. The features will be columns.\n",
    "\n",
    "\"When feature engineering is done, we usually tend to decrease the dimensionality by selecting the \"right\" number of features that capture the essential.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression-Prediction of Salary After Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [ 'ssc_p', 'hsc_p', 'degree_p',  'workex', 'etest_p', 'specialisation', ]\n",
    "output_column = ['salary']\n",
    "\n",
    "X= fe_data[feature_columns]\n",
    "y = fe_data[output_column]\n",
    "\n",
    "# Seperating Features and Target\n",
    "#df_with_fe = df.copy(deep=True)\n",
    "#X = df_with_fe.copy().drop('status', axis=1)\n",
    "#y = df_with_fe['salary']\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# scale each features #Scalizing between 0-1 (Normalization)\n",
    "X_scaled = preprocessing.scale(X)\n",
    "#Scalizing between 0-1 (Normalization)\n",
    "X_scaled = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As different columns have different range of values hence dominance of few columns will be there in dataset. To avoid this we are converting it into standarize format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will train several Machine Learning models and compare their results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression-Prediction of Salary After Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "\n",
    "print('Coefficients: \\n', lm.coef_)\n",
    "print('Intercept: \\n', lm.intercept_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict( X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Create a scatterplot of the real test values versus the predicted values. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,predictions)\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('Predicted Y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate our model performance by calculating the residual sum of squares and the explained variance score (R^2).\n",
    "\n",
    "** Calculate the Mean Absolute Error, Mean Squared Error, and the Root Mean Squared Error. Refer to the lecture or to Wikipedia for the formulas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate these metrics by hand!\n",
    "from sklearn import metrics\n",
    "\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))\n",
    "print('R2:',metrics.explained_variance_score(y_test, predictions))\n",
    "#print('Accuracy After FE:',regr.score(X_test,y_test))\n",
    "print('Accuracy After FE:',lm.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model With OLS approch After Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating Features and Target\n",
    "feature_columns = [ 'ssc_p', 'hsc_p', 'degree_p',  'workex', 'etest_p', 'specialisation', ]\n",
    "output_column = ['salary']\n",
    "\n",
    "x= fe_data[feature_columns]\n",
    "y = fe_data[output_column]\n",
    "\n",
    "\n",
    "#df_with_fe = df.copy(deep=True)\n",
    "#x = df_with_fe.copy().drop('status', axis=1)\n",
    "#y = df_with_fe['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(x,y , test_size=0.2, random_state=42)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = sm.OLS(train_y,train_x.astype(float))\n",
    "results = linear_model.fit()\n",
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = results.predict(test_x)\n",
    "# print(pred_y[:10])\n",
    "# print(test_y[:10])\n",
    "\n",
    "col = ['actual','prediction']\n",
    "\n",
    "prediction = pd.concat([test_y,pred_y],axis=1)\n",
    "prediction.columns = col\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(x = range(0, test_y.size), y=test_y, c = 'blue', label = 'Actual', alpha = 0.3)\n",
    "ax.scatter(x = range(0, pred_y.size), y=pred_y, c = 'red', label = 'Predicted', alpha = 0.3)\n",
    "\n",
    "plt.title('Actual and predicted values')\n",
    "plt.xlabel('Observations')\n",
    "plt.ylabel('Salary')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metircs with OLS and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(test_y, pred_y))\n",
    "print('MSE:', metrics.mean_squared_error(test_y, pred_y))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(test_y, pred_y)))\n",
    "print('R2:',metrics.explained_variance_score(test_y, pred_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Performing Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Details of Linear Regression Before Feature Engineering**\n",
    "\n",
    " MAE: 103097.5828893746,MSE: 23193427141.787605 ,RMSE: 152293.88412470018, R2: 0.31554326001707655 \n",
    "# Accuracy Before FE: 0.3011999997682673\n",
    "\n",
    "#**Details of Linear Regression OLS Approch Before Feature Engineering**\n",
    "\n",
    "MAE: 93772.9896712033,MSE: 14795559262.604927,RMSE: 121636.99791841678,R2: 0.330547092279012\n",
    "\n",
    "# **Details of Linear Regression After Feature Engineering**\n",
    "\n",
    "MAE: 102429.04029170859,MSE: 22435751119.35446,RMSE: 149785.6839599648,R2: 0.33660707882277774\n",
    "# Accuracy After FE: 0.324028191626896\n",
    "\n",
    "#**Details of Linear Regression OLS Approch Before Feature Engineering**\n",
    "\n",
    "\n",
    "MAE: 4.114506719828394e-10,MSE: 1.8157462943665248e-19,RMSE: 4.261157465251108e-10,R2: 0.27202667648457324"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Above we can see the benefit of Feature Engineering, Data with Feature engineering giving better performance and accuracy. However it seems data was already in good shape because there is no much difference in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers of objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1: Which factor influenced a candidate in getting placed?\n",
    "- As per Chi-Squared score **ssc_p** is the most influence factor getting placed\n",
    "- Additionally, **hsc_p, degree_p, workex** feature are from top  features by Chi-Squared and corelation coeficient \n",
    "\n",
    "\n",
    "### 5.2: Do percentage matters for one to get placed? \n",
    "- Yes, percentage is matters while getting placed. ` ssc_p, degree_p, hsc_p` this three part of top five features.\n",
    "- Additionally, as per Chi-Squared score `mba_p` is matter less and this is second least important feature from all features\n",
    "\n",
    "### 5.3: Which degree specialization is much demanded by corporate? \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have seen in while exploring each feature  Mkt&Fin is the more demanded by corporate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "1) Specialisations Matter. Choose the right one.\n",
    "2) Don't worry about grades for salary (although you need them to get placed)\n",
    "3) Degree from Commerce and managemnet will help you (Science and Tech will also work)\n",
    "4) Having work experience is like strawberry on cake. Students having work experience are more likley to get placed\n",
    "5) If a student gets a degree from Science or Tech rather than Communication or Management, the student will have a higher chance of being recruited. Students from these fields have roughly 70% rate of being recruited while other fields have roughly 30%\n",
    "6) The students that specialized in Finance have almost 80% rate of being recruited while HR students have roughly 55%. Therefore, specializing in Finance along with Marketing is a good idea for increasing the chance of being recruited\n",
    "7) If students are academically successful in secondary education they're more likely to be recruited"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
