{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AutoEDA.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN2hYWbCZEHUH2QoCjlHVVB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ov90qMJt16he"},"outputs":[],"source":["Data Cleaning \n","  Redundant sample\n","  Duplicates\n","\n","  Outliers - \n","    Q1-1.5*IQR or Q3+1.5*IQR\n","    sd\n","\n","  Missing -\n","    remove rows\n","    remove columns\n","    Imputation - mean,median,mode, KNN\n","\n","    Mark - missing\n","\n","\n","================\n","1) Data cleaning\n","2) Feature selection\n","3) Data transfomation - power transform , box-cox Transform\n","4) Data/feature engineering - Derive\n","5) Dimensionality reduction\n","\n","2) Feature selection\n","  Domain Knowledge\n","  classification (Categorical)\n","    categorical - chi-square , Mutual Information stats\n","    Numerical - ANOVA F-stats, Mutual Information stats\n","  Regression (Numerical)\n","    Categorical\n","    Numerical - Corrrelation stats, Mutual Information stats\n","\n","\n","\n","\n"]},{"cell_type":"markdown","source":["# Data Leak"],"metadata":{"id":"nUnS24498TO2"}},{"cell_type":"code","source":["from sklearn.datasets import make_classification\n","X, y = make_classification(n_samples=10000,n_features=10)"],"metadata":{"id":"FWOunED-76Xa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install dataprep --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kq1Gubl3LiUy","executionInfo":{"status":"ok","timestamp":1653833923504,"user_tz":-330,"elapsed":34866,"user":{"displayName":"AMIT KUMAR","userId":"17406993422158861440"}},"outputId":"8ba376d9-c8e8-47e8-a82b-3ffb60ca5c75"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 9.5 MB 25.4 MB/s \n","\u001b[K     |████████████████████████████████| 95 kB 4.3 MB/s \n","\u001b[K     |████████████████████████████████| 749 kB 59.2 MB/s \n","\u001b[K     |████████████████████████████████| 366 kB 74.7 MB/s \n","\u001b[K     |████████████████████████████████| 1.0 MB 22.1 MB/s \n","\u001b[K     |████████████████████████████████| 943 kB 61.3 MB/s \n","\u001b[K     |████████████████████████████████| 50 kB 7.9 MB/s \n","\u001b[K     |████████████████████████████████| 965 kB 47.9 MB/s \n","\u001b[K     |████████████████████████████████| 11.1 MB 55.7 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 49.1 MB/s \n","\u001b[K     |████████████████████████████████| 78 kB 4.6 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 133 kB 70.3 MB/s \n","\u001b[K     |████████████████████████████████| 1.5 MB 56.7 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 47.6 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 58.3 MB/s \n","\u001b[K     |████████████████████████████████| 94 kB 4.2 MB/s \n","\u001b[K     |████████████████████████████████| 140 kB 59.7 MB/s \n","\u001b[K     |████████████████████████████████| 224 kB 65.7 MB/s \n","\u001b[K     |████████████████████████████████| 96 kB 7.2 MB/s \n","\u001b[K     |████████████████████████████████| 49 kB 6.6 MB/s \n","\u001b[?25h  Building wheel for metaphone (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pystache (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n"]}]},{"cell_type":"code","source":["from dataprep.datasets import load_dataset\n","from dataprep.eda import create_report\n","df = load_dataset(\"titanic\")\n","report = create_report(df)\n","report.save(\"titanic.html\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UF5H0F4GLi7h","executionInfo":{"status":"ok","timestamp":1653833947428,"user_tz":-330,"elapsed":5238,"user":{"displayName":"AMIT KUMAR","userId":"17406993422158861440"}},"outputId":"f8bc5bdc-bf39-4135-c894-8c36db391801"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Report has been saved to titanic.html!\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"dY58gpTMLmIp"},"execution_count":null,"outputs":[]}]}